{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Loading and Cleaning Data"
      ],
      "metadata": {
        "id": "-m5D5Xa6IuFm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "file_path = \"/content/drive/My Drive/cleaned_data_combined_modified.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "id": "DcCtK3WS66h-",
        "outputId": "353e311d-83bf-4bb3-906f-8e3886a32c56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       id  \\\n",
              "0  716549   \n",
              "1  715742   \n",
              "2  727333   \n",
              "3  606874   \n",
              "4  505318   \n",
              "\n",
              "   Q1: From a scale 1 to 5, how complex is it to make this food? (Where 1 is the most simple, and 5 is the most complex)  \\\n",
              "0                                                  3                                                                       \n",
              "1                                                  4                                                                       \n",
              "2                                                  3                                                                       \n",
              "3                                                  4                                                                       \n",
              "4                                                  2                                                                       \n",
              "\n",
              "  Q2: How many ingredients would you expect this food item to contain?  \\\n",
              "0                                                  6                     \n",
              "1                                        bread, meet                     \n",
              "2                                                  5                     \n",
              "3                                              7-Jun                     \n",
              "4                                          3 or more                     \n",
              "\n",
              "  Q3: In what setting would you expect this food to be served? Please check all that apply  \\\n",
              "0         Week day lunch,At a party,Late night snack                                         \n",
              "1         Week day lunch,At a party,Late night snack                                         \n",
              "2  Week day lunch,Week day dinner,Weekend lunch,W...                                         \n",
              "3  Week day lunch,Week day dinner,Weekend lunch,W...                                         \n",
              "4  Week day lunch,Week day dinner,Weekend lunch,W...                                         \n",
              "\n",
              "  Q4: How much would you expect to pay for one serving of this food item?  \\\n",
              "0                                                  5                        \n",
              "1                               5$ for a large piece                        \n",
              "2                                           10dollar                        \n",
              "3                                                $3                         \n",
              "4                                                $5                         \n",
              "\n",
              "  Q5: What movie do you think of when thinking of this food item?  \\\n",
              "0                  Cloudy with a Chance of Meatballs                \n",
              "1              All sort of american young boy movies                \n",
              "2                                       action movie                \n",
              "3                                          Mamma Mia                \n",
              "4                  Cloudy with a chance of meatballs                \n",
              "\n",
              "  Q6: What drink would you pair with this food item?  \\\n",
              "0                                              CokeÂ    \n",
              "1                                               Coke   \n",
              "2                                               cola   \n",
              "3                                               Soda   \n",
              "4                                               Soda   \n",
              "\n",
              "  Q7: When you think about this food item, who does it remind you of?  \\\n",
              "0                                            Friends                    \n",
              "1                         Friends,Teachers,Strangers                    \n",
              "2                                            Friends                    \n",
              "3                          Siblings,Friends,Teachers                    \n",
              "4                                   Siblings,Friends                    \n",
              "\n",
              "  Q8: How much hot sauce would you add to this food item?  Label  \n",
              "0                                    A little (mild)       Pizza  \n",
              "1                                                NaN       Pizza  \n",
              "2                         A moderate amount (medium)       Pizza  \n",
              "3  I will have some of this food item with my hot...       Pizza  \n",
              "4                                    A little (mild)       Pizza  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f3c3185a-c22f-4ce3-adbc-f0de339a1cc0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Q1: From a scale 1 to 5, how complex is it to make this food? (Where 1 is the most simple, and 5 is the most complex)</th>\n",
              "      <th>Q2: How many ingredients would you expect this food item to contain?</th>\n",
              "      <th>Q3: In what setting would you expect this food to be served? Please check all that apply</th>\n",
              "      <th>Q4: How much would you expect to pay for one serving of this food item?</th>\n",
              "      <th>Q5: What movie do you think of when thinking of this food item?</th>\n",
              "      <th>Q6: What drink would you pair with this food item?</th>\n",
              "      <th>Q7: When you think about this food item, who does it remind you of?</th>\n",
              "      <th>Q8: How much hot sauce would you add to this food item?</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>716549</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>Week day lunch,At a party,Late night snack</td>\n",
              "      <td>5</td>\n",
              "      <td>Cloudy with a Chance of Meatballs</td>\n",
              "      <td>Coke</td>\n",
              "      <td>Friends</td>\n",
              "      <td>A little (mild)</td>\n",
              "      <td>Pizza</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>715742</td>\n",
              "      <td>4</td>\n",
              "      <td>bread, meet</td>\n",
              "      <td>Week day lunch,At a party,Late night snack</td>\n",
              "      <td>5$ for a large piece</td>\n",
              "      <td>All sort of american young boy movies</td>\n",
              "      <td>Coke</td>\n",
              "      <td>Friends,Teachers,Strangers</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pizza</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>727333</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>Week day lunch,Week day dinner,Weekend lunch,W...</td>\n",
              "      <td>10dollar</td>\n",
              "      <td>action movie</td>\n",
              "      <td>cola</td>\n",
              "      <td>Friends</td>\n",
              "      <td>A moderate amount (medium)</td>\n",
              "      <td>Pizza</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>606874</td>\n",
              "      <td>4</td>\n",
              "      <td>7-Jun</td>\n",
              "      <td>Week day lunch,Week day dinner,Weekend lunch,W...</td>\n",
              "      <td>$3</td>\n",
              "      <td>Mamma Mia</td>\n",
              "      <td>Soda</td>\n",
              "      <td>Siblings,Friends,Teachers</td>\n",
              "      <td>I will have some of this food item with my hot...</td>\n",
              "      <td>Pizza</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>505318</td>\n",
              "      <td>2</td>\n",
              "      <td>3 or more</td>\n",
              "      <td>Week day lunch,Week day dinner,Weekend lunch,W...</td>\n",
              "      <td>$5</td>\n",
              "      <td>Cloudy with a chance of meatballs</td>\n",
              "      <td>Soda</td>\n",
              "      <td>Siblings,Friends</td>\n",
              "      <td>A little (mild)</td>\n",
              "      <td>Pizza</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f3c3185a-c22f-4ce3-adbc-f0de339a1cc0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f3c3185a-c22f-4ce3-adbc-f0de339a1cc0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f3c3185a-c22f-4ce3-adbc-f0de339a1cc0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-dd4d63a8-c296-491a-af4a-0da2bcc07b41\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dd4d63a8-c296-491a-af4a-0da2bcc07b41')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-dd4d63a8-c296-491a-af4a-0da2bcc07b41 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1644,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 125479,\n        \"min\": 5978,\n        \"max\": 854745,\n        \"num_unique_values\": 548,\n        \"samples\": [\n          523710,\n          631507,\n          629285\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Q1: From a scale 1 to 5, how complex is it to make this food? (Where 1 is the most simple, and 5 is the most complex)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          4,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Q2: How many ingredients would you expect this food item to contain?\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 493,\n        \"samples\": [\n          \"Rice, fish, wasabi, seaweed, salt, soy sauce.\\n\\natleast 6\",\n          \"Around 6-8, not including spices/seasoning\",\n          \"10+\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Q3: In what setting would you expect this food to be served? Please check all that apply\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 60,\n        \"samples\": [\n          \"Week day lunch,At a party,Late night snack\",\n          \"Week day dinner,Weekend lunch,Weekend dinner,At a party,Late night snack\",\n          \"Week day lunch,Week day dinner,Weekend lunch,Late night snack\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Q4: How much would you expect to pay for one serving of this food item?\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 586,\n        \"samples\": [\n          \"A box of sushi would be around 8 dollar.\",\n          \"$20 maximum for a large pizza filled with toppings such as Chicken.\\u00a0\",\n          \"10 dollars.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Q5: What movie do you think of when thinking of this food item?\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 769,\n        \"samples\": [\n          \"Pokemon\",\n          \"A Silent Voice (2016)\",\n          \"Avengers (2012)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Q6: What drink would you pair with this food item?\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 428,\n        \"samples\": [\n          \"Ocha\",\n          \"Lemonade\",\n          \"milk\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Q7: When you think about this food item, who does it remind you of?\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 29,\n        \"samples\": [\n          \"Siblings,Strangers\",\n          \"Siblings,Friends,Strangers\",\n          \"Parents,Friends,Teachers\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Q8: How much hot sauce would you add to this food item?\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"A moderate amount (medium)\",\n          \"A lot (hot)\",\n          \"A little (mild)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Pizza\",\n          \"Shawarma\",\n          \"Sushi\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/My Drive/cleaned_data_combined_modified.csv\")\n",
        "\n",
        "def extract_numeric(value):\n",
        "    if pd.isnull(value):\n",
        "        return None\n",
        "    value = str(value).strip().lower()\n",
        "    value = re.sub(r'[^\\d\\.\\-]', ' ', value)\n",
        "    value = re.sub(r'\\s+', ' ', value).strip()\n",
        "\n",
        "    if '-' in value:\n",
        "        numbers = [float(num) for num in value.split('-') if num.strip().isdigit()]\n",
        "        if numbers:\n",
        "            return sum(numbers) / len(numbers)\n",
        "\n",
        "    match = re.search(r'\\d+(\\.\\d+)?', value)\n",
        "    return float(match.group()) if match else None\n",
        "\n",
        "numerical_columns = [\n",
        "    \"Q1: From a scale 1 to 5, how complex is it to make this food? (Where 1 is the most simple, and 5 is the most complex)\",\n",
        "    \"Q2: How many ingredients would you expect this food item to contain?\",\n",
        "    \"Q4: How much would you expect to pay for one serving of this food item?\"\n",
        "]\n",
        "\n",
        "for col in numerical_columns:\n",
        "    df[col] = df[col].apply(extract_numeric)\n",
        "\n",
        "df[numerical_columns] = df[numerical_columns].fillna(df[numerical_columns].mean())\n",
        "\n",
        "text_cols = [\"Q3: In what setting would you expect this food to be served? Please check all that apply\",\n",
        "             \"Q5: What movie do you think of when thinking of this food item?\",\n",
        "             \"Q6: What drink would you pair with this food item?\",\n",
        "             \"Q7: When you think about this food item, who does it remind you of?\"]\n",
        "\n",
        "df[text_cols] = df[text_cols].fillna(\"none\").astype(str).apply(lambda x: x.str.lower().str.strip())\n",
        "\n",
        "vectorizer_q3 = CountVectorizer(binary=True)\n",
        "vectorizer_q5 = CountVectorizer(binary=True)\n",
        "vectorizer_q6 = CountVectorizer(binary=True)\n",
        "vectorizer_q7 = CountVectorizer(binary=True)\n",
        "\n",
        "Q3_bow = vectorizer_q3.fit_transform(df[\"Q3: In what setting would you expect this food to be served? Please check all that apply\"])\n",
        "Q5_bow = vectorizer_q5.fit_transform(df[\"Q5: What movie do you think of when thinking of this food item?\"])\n",
        "Q6_bow = vectorizer_q6.fit_transform(df[\"Q6: What drink would you pair with this food item?\"])\n",
        "Q7_bow = vectorizer_q7.fit_transform(df[\"Q7: When you think about this food item, who does it remind you of?\"])\n",
        "\n",
        "df_q3_bow = pd.DataFrame(Q3_bow.toarray(), columns=[f\"Q3_{word}\" for word in vectorizer_q3.get_feature_names_out()])\n",
        "df_q5_bow = pd.DataFrame(Q5_bow.toarray(), columns=[f\"Q5_{word}\" for word in vectorizer_q5.get_feature_names_out()])\n",
        "df_q6_bow = pd.DataFrame(Q6_bow.toarray(), columns=[f\"Q6_{word}\" for word in vectorizer_q6.get_feature_names_out()])\n",
        "df_q7_bow = pd.DataFrame(Q7_bow.toarray(), columns=[f\"Q7_{word}\" for word in vectorizer_q7.get_feature_names_out()])\n",
        "\n",
        "df = pd.concat([df, df_q3_bow, df_q5_bow, df_q6_bow, df_q7_bow], axis=1)\n",
        "\n",
        "df.drop(columns=text_cols, inplace=True)\n",
        "\n",
        "hot_sauce_map = {\n",
        "    \"A little (mild)\": \"Mild\",\n",
        "    \"A moderate amount (medium)\": \"Medium\",\n",
        "    \"A lot (hot)\": \"Hot\",\n",
        "    \"I will have some of this food item with my hot sauce\": \"Medium\"\n",
        "}\n",
        "\n",
        "df[\"Q8_cleaned\"] = df[\"Q8: How much hot sauce would you add to this food item?\"].map(hot_sauce_map)\n",
        "df[\"Q8_cleaned\"].fillna(\"None\", inplace=True)\n",
        "df = pd.get_dummies(df, columns=[\"Q8_cleaned\"])\n",
        "df.drop(columns=[\"Q8: How much hot sauce would you add to this food item?\"], inplace=True)\n",
        "\n",
        "df.to_csv(\"/content/drive/My Drive/cleaned_data_bow.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QH-o7HmRlu_S",
        "outputId": "9b1ca375-9553-4f1e-c51b-dcbce4a10723"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-476ad391ded6>:66: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[\"Q8_cleaned\"].fillna(\"None\", inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Selection Functions\n",
        "\n",
        "First, we implement a chi2 function to determine best features.\n",
        "\n",
        "This includes calculation of p values."
      ],
      "metadata": {
        "id": "WfLh5yTOI2Gq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def gamma(x):\n",
        "    \"\"\"Gamma function using Stirling's approximation for large x.\"\"\"\n",
        "    if x < 0:\n",
        "        raise ValueError(\"x must be positive\")\n",
        "    elif x == 1 or x == 2:\n",
        "        return 1\n",
        "    else:\n",
        "        # Stirling's approximation for large x\n",
        "        return np.sqrt(2 * np.pi * x) * (x / np.e) ** x\n",
        "\n",
        "def chi_squared_cdf(x, df, num_steps=1000):\n",
        "    \"\"\"\n",
        "    Approximate the CDF of the chi-squared distribution using numerical integration.\n",
        "    This is based on the Gamma distribution CDF approximation.\n",
        "\n",
        "    x: chi-squared statistic\n",
        "    df: degrees of freedom\n",
        "    num_steps: number of steps in the numerical integration\n",
        "    \"\"\"\n",
        "    # Gamma function approximation using the incomplete gamma function (via numerical integration)\n",
        "    step_size = x / num_steps\n",
        "    integral = 0.0\n",
        "    for i in range(num_steps):\n",
        "        t = i * step_size\n",
        "        # Gamma probability density function (PDF) for chi-squared distribution\n",
        "        gamma_pdf = (t ** (df / 2 - 1) * np.exp(-t / 2)) / (2 ** (df / 2) * gamma(df / 2))\n",
        "        integral += gamma_pdf * step_size\n",
        "    return integral\n",
        "\n",
        "def chi_squared_p_value(chi2_stats, df):\n",
        "    \"\"\"\n",
        "    Calculate the p-value for a vector of chi-squared statistics based on the chi-squared CDF.\n",
        "    chi2_stats: a vector of chi-squared statistics\n",
        "    df: degrees of freedom\n",
        "    \"\"\"\n",
        "    p_values = []\n",
        "    for chi2_stat in chi2_stats:\n",
        "        cdf_value = chi_squared_cdf(chi2_stat, df)\n",
        "        p_value = 1 - cdf_value\n",
        "        p_values.append(p_value)\n",
        "    return np.array(p_values)\n",
        "\n",
        "def chi2_statistic(X, y):\n",
        "    \"\"\"\n",
        "    Compute the chi-squared statistic for each feature in X with respect to the target vector y.\n",
        "\n",
        "    Parameters:\n",
        "    X: numpy array of shape (n_samples, n_features), feature matrix\n",
        "    y: numpy array of shape (n_samples,), target vector (class labels)\n",
        "\n",
        "    Returns:\n",
        "    chi2_stats: numpy array of shape (n_features,), chi-squared statistics for each feature\n",
        "    \"\"\"\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    n_samples, n_features = X.shape\n",
        "    n_classes = len(np.unique(y))  # Number of unique classes in the target vector\n",
        "\n",
        "    chi2_stats = np.zeros(n_features)  # Array to store chi-squared statistics for each feature\n",
        "\n",
        "    # Loop over each feature to calculate its chi-squared statistic\n",
        "    for i in range(n_features):\n",
        "        observed = np.zeros((n_classes, 2))  # Observed counts for each class (rows) and feature (columns)\n",
        "        for j in range(n_samples):\n",
        "            match y[j]:\n",
        "              case \"Pizza\":\n",
        "                  y_index = 0\n",
        "              case \"Sushi\":\n",
        "                  y_index = 1\n",
        "              case \"Shawarma\":\n",
        "                  y_index = 2\n",
        "            observed[y_index, int(X[j, i])] += 1  # Increment the count for the corresponding class and feature value\n",
        "\n",
        "        # Calculate row sums and column sums\n",
        "        row_sums = observed.sum(axis=1)  # Sum of each class (target)\n",
        "        col_sums = observed.sum(axis=0)  # Sum of each feature value\n",
        "        total_sum = observed.sum()  # Total sum of all counts\n",
        "\n",
        "        # Calculate expected frequencies\n",
        "        expected = []\n",
        "        for k in range(3):\n",
        "          expected.append([0.00000001 if x == 0 else x for x in (np.outer(row_sums, col_sums) / total_sum)[k]])\n",
        "        expected = np.array(expected)\n",
        "        # Calculate chi-squared statistic for the feature\n",
        "        chi2_stat = np.sum((observed - expected) ** 2 / expected)\n",
        "        chi2_stats[i] = chi2_stat\n",
        "\n",
        "    return np.array(chi2_stats), chi_squared_p_value(chi2_stats, len(observed) - 1)"
      ],
      "metadata": {
        "id": "DrraOtbTCAQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Select the K best features; ie the features with the highest chi2 values."
      ],
      "metadata": {
        "id": "L91lPgQTJdOy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def select_k_best(X, y, k, classification=\"chi2\"):\n",
        "  chi2_vals, p_vals = chi2_statistic(X, y)\n",
        "  if classification == \"chi2\":\n",
        "    k_best = np.argpartition(chi2_vals, -1*k)[-1*k:]\n",
        "  if classification == \"p\":\n",
        "    k_best = np.argpartition(p_vals, k)[:k]\n",
        "\n",
        "  columns = X.shape[1]\n",
        "  for i in range(columns):\n",
        "    index = columns - i - 1\n",
        "    if index not in k_best:\n",
        "      X = np.delete(X, index, 1)\n",
        "  return X"
      ],
      "metadata": {
        "id": "cadD3HSnItSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Implementation\n",
        "Naive Bayes class implementation."
      ],
      "metadata": {
        "id": "u9l19RipJ6tZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NaiveBayes():\n",
        "  def __init__(self, *, a=2, b=2, split=90, N=100) -> None:\n",
        "     self.a = a\n",
        "     self.b = b\n",
        "     self.split = split\n",
        "     self.N = int(N)\n",
        "\n",
        "  def _map_pi_theta(self, X, y):\n",
        "    a = self.a\n",
        "    b = self.b\n",
        "    N, vocab_size = X.shape[0], X.shape[1]\n",
        "    pi = 0\n",
        "    theta = np.zeros([vocab_size, 3])\n",
        "\n",
        "    X_pizza = X[y == \"Pizza\"]\n",
        "    X_sushi = X[y == \"Sushi\"]\n",
        "    X_shawarma = X[y == \"Shawarma\"]\n",
        "\n",
        "    N_pizza = X_pizza.shape[0]\n",
        "    N_sushi = X_sushi.shape[0]\n",
        "    N_shawarma = X_shawarma.shape[0]\n",
        "\n",
        "    theta[:, 0] = (np.matmul(np.transpose(X_pizza), np.ones(N_pizza)) + a - 1) / (N_pizza + a + b - 2)\n",
        "    theta[:, 1] = (np.matmul(np.transpose(X_sushi), np.ones(N_sushi)) + a - 1) / (N_sushi + a + b - 2)\n",
        "    theta[:, 2] = (np.matmul(np.transpose(X_shawarma), np.ones(N_shawarma)) + a - 1) / (N_shawarma + a + b - 2)\n",
        "\n",
        "    pi = [N_pizza/N, N_sushi/N, N_shawarma/N]\n",
        "\n",
        "    return pi, theta\n",
        "\n",
        "  def _training_subset(self, X, y):\n",
        "    percent_split = self.split\n",
        "    X_random = np.array(X.copy())\n",
        "    y_random = np.array(y.copy())\n",
        "\n",
        "    p = np.random.permutation(len(y_random))\n",
        "    X_random, y_random = X_random[p], y_random[p]\n",
        "\n",
        "    slice1 = int(np.floor(percent_split * len(y_random) / 100))\n",
        "    return X_random[:slice1], y_random[:slice1]\n",
        "\n",
        "  def _single_prediction(self, X, pi, theta, random):\n",
        "    results = []\n",
        "\n",
        "    log_shawarma = np.matmul(X, np.log(theta[:, 2])) + np.matmul(1-X, np.log(1-theta[:,2]))\n",
        "    results.append(pi[2] * np.exp(log_shawarma))\n",
        "    log_pizza = np.matmul(X, np.log(theta[:, 0])) + np.matmul(1-X, np.log(1-theta[:,0]))\n",
        "    results.append(pi[0] * np.exp(log_pizza))\n",
        "    log_sushi = np.matmul(X, np.log(theta[:, 1])) + np.matmul(1-X, np.log(1-theta[:,1]))\n",
        "    results.append(pi[1] * np.exp(log_sushi))\n",
        "\n",
        "    if random == True:\n",
        "      y = self.argmax_with_tie_breaking(results)\n",
        "    else:\n",
        "      y = np.argmax(results, axis = 0)\n",
        "    return y\n",
        "\n",
        "  def argmax_with_tie_breaking(self, array):\n",
        "    result = []\n",
        "    for item in np.array(array).T:\n",
        "      max_value = np.max(item)\n",
        "      max_indices = np.where(item == max_value)[0]\n",
        "      if len(max_indices) > 1:\n",
        "        print(f\"Tie detected for values: {item[max_indices]} at indices: {max_indices}\")\n",
        "      result.append(np.random.choice(max_indices))\n",
        "    return np.array(result)\n",
        "\n",
        "  def fit(self, X, y, sample_weight=None):\n",
        "    #random.seed(35)\n",
        "    pi_map = []\n",
        "    theta_map = []\n",
        "    N = self.N\n",
        "    for i in range(N):\n",
        "        X_batch, y_batch = self._training_subset(X, y)\n",
        "        pi_map_temp, theta_map_temp = self._map_pi_theta(X_batch, y_batch)\n",
        "        pi_map.append(pi_map_temp)\n",
        "        theta_map.append(theta_map_temp)\n",
        "\n",
        "    self.pi_map = np.mean(pi_map, axis=0)\n",
        "    self.theta_map = np.mean(theta_map, axis=0)\n",
        "    return self\n",
        "\n",
        "  def predict(self, X, random=True):\n",
        "    N = self.N\n",
        "    pi = self.pi_map\n",
        "    theta = self.theta_map\n",
        "    y_temp = self._single_prediction(X, pi, theta, random)\n",
        "\n",
        "    y_map = [\"Shawarma\" if x==0 else \"Pizza\" if x==1 else \"Sushi\" for x in y_temp]\n",
        "    return np.array(y_map)\n",
        "\n",
        "  def get_params(self, deep=True):\n",
        "    return {\"a\": self.a, \"b\": self.b, \"N\": self.N, \"split\": self.split}\n",
        "\n",
        "  def set_params(self, **parameters):\n",
        "    for parameter, value in parameters.items():\n",
        "      setattr(self, parameter, value)\n",
        "    return self"
      ],
      "metadata": {
        "id": "nLbOzL1lLckf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Voting Classifier takes in a list of models and returns the majority vote when\n",
        "making predictions."
      ],
      "metadata": {
        "id": "yLpTR8-tKGQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VotingClassifier2():\n",
        "  def __init__(self, estimators, voting) -> None:\n",
        "      self.models = {}\n",
        "      self.num_models = 0\n",
        "      for item in estimators:\n",
        "        self.models[item[0]] = item[1]\n",
        "        self.num_models += 1\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    for item in self.models:\n",
        "      self.models[item].fit(X, y)\n",
        "    return self\n",
        "\n",
        "  def argmax_with_tie_breaking(self, array):\n",
        "    result = []\n",
        "    for item in np.array(array).T:\n",
        "      max_value = np.max(item)\n",
        "      max_indices = np.where(item == max_value)[0]\n",
        "      result.append(np.random.choice(max_indices))\n",
        "    return np.array(result)\n",
        "\n",
        "  def predict(self, X, random=True):\n",
        "    predictions = []\n",
        "    y_map_count = np.zeros([3, X.shape[0]])\n",
        "    for key in self.models:\n",
        "        model = self.models[key]\n",
        "        y_temp = model.predict(X)\n",
        "        for i in range(y_temp.shape[0]):\n",
        "          value = y_temp[i]\n",
        "          if value == \"Pizza\":\n",
        "            y_map_count[0][i] += 1\n",
        "          if value == \"Sushi\":\n",
        "            y_map_count[1][i] += 1\n",
        "          if value == \"Shawarma\":\n",
        "            y_map_count[2][i] += 1\n",
        "    if random:\n",
        "      y_map = self.argmax_with_tie_breaking(y_map_count)\n",
        "    else:\n",
        "      y_map = np.argmax(y_map_count, axis = 0)\n",
        "    y_map = [\"Pizza\" if x==0 else \"Sushi\" if x==1 else \"Shawarma\" for x in y_map]\n",
        "    return np.array(y_map)"
      ],
      "metadata": {
        "id": "-at2DDhEQjpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Return the accuracy of predictions."
      ],
      "metadata": {
        "id": "QvrQRRNGKTj2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(y, t):\n",
        "    return np.mean(y == t)"
      ],
      "metadata": {
        "id": "BYxPZ6cseerW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Putting it all together"
      ],
      "metadata": {
        "id": "p-GYtc0HKXnD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "\n",
        "# 1 Load Data\n",
        "df = pd.read_csv(\"/content/drive/My Drive/cleaned_data_bow.csv\")\n",
        "df = df.dropna(subset=[\"Label\"])\n",
        "\n",
        "# 2 Separate Features and Labels\n",
        "X = df.drop(columns=[\"Label\"])\n",
        "y = df[\"Label\"]\n",
        "\n",
        "# 3 Identify Numeric and Text Columns\n",
        "numeric_columns = [col for col in X.columns if X[col].dtype in [\"int64\", \"float64\"]]\n",
        "bow_columns = [col for col in X.columns if col not in numeric_columns]\n",
        "\n",
        "# 4 Apply TF-IDF Transformation\n",
        "tfidf = TfidfTransformer()\n",
        "X_tfidf = tfidf.fit_transform(X[bow_columns])\n",
        "df_tfidf = pd.DataFrame(X_tfidf.toarray(), columns=bow_columns, index=X.index)\n",
        "\n",
        "# 5 Min-Max Scaling for Numeric Features\n",
        "if numeric_columns:\n",
        "    scaler = MinMaxScaler()\n",
        "    df_scaled = pd.DataFrame(scaler.fit_transform(X[numeric_columns]), columns=numeric_columns, index=X.index)\n",
        "    X_temp = pd.concat([df_tfidf, df_scaled], axis=1)\n",
        "else:\n",
        "    X_temp = df_tfidf"
      ],
      "metadata": {
        "id": "FsnjB-a27dvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k_best = SelectKBest(chi2, k=500)\n",
        "X_final = k_best.fit_transform(X_temp, y)\n",
        "#X_final = select_k_best(X_temp, y, 750)\n",
        "#X_final = np.array(X_temp)\n",
        "\n",
        "# 7 Train-Test Split (Stratified Split)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_final, y, test_size=0.3, random_state=42, stratify=y)"
      ],
      "metadata": {
        "id": "UcYNIh4VNLCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8 Hyperparameter Tuning for Naive Bayes\n",
        "'''\n",
        "param_grid_nb = {'alpha': np.linspace(0.1, 1.0, 10)}  # Testing alpha values between 0.1 and 1.0\n",
        "grid_search_nb = GridSearchCV(MultinomialNB(), param_grid_nb, cv=5, scoring=\"accuracy\")\n",
        "grid_search_nb.fit(X_train, y_train)\n",
        "\n",
        "best_alpha = grid_search_nb.best_params_['alpha']\n",
        "print(f\"Best Alpha Found for Naive Bayes: {best_alpha}\")\n",
        "\n",
        "split=90, n_iter=100'''\n",
        "param_grid_nb = {'split': np.linspace(10, 90, 9), 'N': [25, 50, 75, 100, 200, 250, 500]}\n",
        "grid_search_nb = GridSearchCV(NaiveBayes(), param_grid_nb, cv=5, scoring=\"accuracy\")\n",
        "grid_search_nb.fit(X_train, y_train)\n",
        "\n",
        "best_nb = grid_search_nb.best_params_\n",
        "print(f\"Best Params Found for Naive Bayes: {best_nb}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBGAzodL9Ja_",
        "outputId": "4384d5a2-9c88-4d03-f107-afbd890a73f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Params Found for Naive Bayes: {'N': 75, 'split': np.float64(90.0)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 9 Hyperparameter Tuning for Random Forest\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "grid_search_rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid_rf, cv=5, scoring=\"accuracy\")\n",
        "grid_search_rf.fit(X_train, y_train)\n",
        "\n",
        "best_rf_params = grid_search_rf.best_params_\n",
        "print(f\"Best Random Forest Parameters: {best_rf_params}\")\n",
        "\n",
        "# 10 Hyperparameter Tuning for Logistic Regression\n",
        "param_grid_lr = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'solver': ['liblinear', 'saga']\n",
        "}\n",
        "grid_search_lr = GridSearchCV(LogisticRegression(), param_grid_lr, cv=5, scoring=\"accuracy\")\n",
        "grid_search_lr.fit(X_train, y_train)\n",
        "\n",
        "best_lr_params = grid_search_lr.best_params_\n",
        "print(f\"Best Logistic Regression Parameters: {best_lr_params}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaUCgufnm1au",
        "outputId": "a5c49a00-3777-4f27-b256-b1f069567a99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 200}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Logistic Regression Parameters: {'C': 10, 'solver': 'liblinear'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 11 Train Models with Best Hyperparameters\n",
        "# nb_model = MultinomialNB(alpha=best_alpha)\n",
        "nb_model = NaiveBayes(split=90, N=50)"
      ],
      "metadata": {
        "id": "Nx8lhfVFIXLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 12 Create Voting Classifier with Naive Bayes, Random Forest, and Logistic Regression\n",
        "nb_model.fit(X_train, y_train)\n",
        "\n",
        "# 13 Make Predictions\n",
        "y_train_pred = nb_model.predict(X_train, random=True)\n",
        "y_test_pred = nb_model.predict(X_test, random=True)\n",
        "\n",
        "# 14 Evaluate Performance\n",
        "train_accuracy = accuracy(y_train, y_train_pred)\n",
        "test_accuracy = accuracy(y_test, y_test_pred)\n",
        "\n",
        "print(f\"\\nTraining Accuracy: {train_accuracy:.4f}\")\n",
        "print(f\"Testing Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "print(\"\\nClassification Report (Test Set):\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_test_pred)\n",
        "print(cm)\n",
        "\n",
        "\n",
        "# 13 Make Predictions\n",
        "y_train_pred = nb_model.predict(X_train, random=False)\n",
        "y_test_pred = nb_model.predict(X_test, random=False)\n",
        "\n",
        "# 14 Evaluate Performance\n",
        "train_accuracy = accuracy(y_train, y_train_pred)\n",
        "test_accuracy = accuracy(y_test, y_test_pred)\n",
        "\n",
        "print(f\"\\nTraining Accuracy: {train_accuracy:.4f}\")\n",
        "print(f\"Testing Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "print(\"\\nClassification Report (Test Set):\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "\n",
        "cm = confusion_matrix(y_test, y_test_pred)\n",
        "print(cm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yRFWFdIuuTn",
        "outputId": "f8f9b24a-7308-4a16-8822-9bb9dec900d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Accuracy: 0.9035\n",
            "Testing Accuracy: 0.8947\n",
            "\n",
            "Classification Report (Test Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Pizza       0.85      0.95      0.90       164\n",
            "    Shawarma       0.90      0.90      0.90       165\n",
            "       Sushi       0.94      0.84      0.89       165\n",
            "\n",
            "    accuracy                           0.89       494\n",
            "   macro avg       0.90      0.89      0.89       494\n",
            "weighted avg       0.90      0.89      0.89       494\n",
            "\n",
            "[[155   6   3]\n",
            " [ 11 148   6]\n",
            " [ 16  10 139]]\n",
            "\n",
            "Training Accuracy: 0.9035\n",
            "Testing Accuracy: 0.8947\n",
            "\n",
            "Classification Report (Test Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Pizza       0.85      0.95      0.90       164\n",
            "    Shawarma       0.90      0.90      0.90       165\n",
            "       Sushi       0.94      0.84      0.89       165\n",
            "\n",
            "    accuracy                           0.89       494\n",
            "   macro avg       0.90      0.89      0.89       494\n",
            "weighted avg       0.90      0.89      0.89       494\n",
            "\n",
            "[[155   6   3]\n",
            " [ 11 148   6]\n",
            " [ 16  10 139]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf_model = RandomForestClassifier(n_estimators=best_rf_params['n_estimators'],\n",
        "                                  max_depth=best_rf_params['max_depth'],\n",
        "                                  min_samples_split=best_rf_params['min_samples_split'],\n",
        "                                  random_state=42)\n",
        "lr_model = LogisticRegression(C=best_lr_params['C'], solver=best_lr_params['solver'])"
      ],
      "metadata": {
        "id": "Krzs8HqoIOJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 12 Create Voting Classifier with Naive Bayes, Random Forest, and Logistic Regression\n",
        "voting_model = VotingClassifier2(estimators=[('nb', nb_model), ('rf', rf_model), ('lr', lr_model)], voting='hard')\n",
        "voting_model.fit(X_train, y_train)\n",
        "\n",
        "# 13 Make Predictions\n",
        "y_train_pred = voting_model.predict(X_train)\n",
        "y_test_pred = voting_model.predict(X_test)\n",
        "\n",
        "# 14 Evaluate Performance\n",
        "train_accuracy = accuracy(y_train, y_train_pred)\n",
        "test_accuracy = accuracy(y_test, y_test_pred)\n",
        "\n",
        "print(y_test)\n",
        "\n",
        "print(f\"\\nTraining Accuracy: {train_accuracy:.4f}\")\n",
        "print(f\"Testing Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "print(\"\\nClassification Report (Test Set):\")\n",
        "print(classification_report(y_test, y_test_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pv-ljogMy4K1",
        "outputId": "c0ad1eed-aa2b-49d5-e6bd-b1fde76c3877"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "213        Pizza\n",
            "745        Pizza\n",
            "758        Pizza\n",
            "216        Pizza\n",
            "1127    Shawarma\n",
            "          ...   \n",
            "1091    Shawarma\n",
            "1080    Shawarma\n",
            "121        Pizza\n",
            "532        Sushi\n",
            "1432       Sushi\n",
            "Name: Label, Length: 494, dtype: object\n",
            "\n",
            "Training Accuracy: 0.9678\n",
            "Testing Accuracy: 0.9089\n",
            "\n",
            "Classification Report (Test Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Pizza       0.88      0.95      0.91       164\n",
            "    Shawarma       0.92      0.90      0.91       165\n",
            "       Sushi       0.94      0.88      0.91       165\n",
            "\n",
            "    accuracy                           0.91       494\n",
            "   macro avg       0.91      0.91      0.91       494\n",
            "weighted avg       0.91      0.91      0.91       494\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from NaiveBayes import NaiveBayesClassifier\n",
        "\n",
        "nb_model = NaiveBayesClassifier(split=90, N=50)\n",
        "\n",
        "nb_model.fit(X_train, y_train)\n",
        "\n",
        "# 13 Make Predictions\n",
        "y_train_pred = nb_model.predict(X_train)\n",
        "y_test_pred = nb_model.predict(X_test)\n",
        "\n",
        "# 14 Evaluate Performance\n",
        "train_accuracy = accuracy(y_train, y_train_pred)\n",
        "test_accuracy = accuracy(y_test, y_test_pred)\n",
        "\n",
        "print(f\"\\nTraining Accuracy: {train_accuracy:.4f}\")\n",
        "print(f\"Testing Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "print(\"\\nClassification Report (Test Set):\")\n",
        "print(classification_report(y_test, y_test_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTuIXo9eif0f",
        "outputId": "04f3f6df-63b1-429e-e529-8ddac469dac8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Accuracy: 0.9035\n",
            "Testing Accuracy: 0.8927\n",
            "\n",
            "Classification Report (Test Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Pizza       0.86      0.94      0.90       164\n",
            "    Shawarma       0.90      0.90      0.90       165\n",
            "       Sushi       0.93      0.84      0.89       165\n",
            "\n",
            "    accuracy                           0.89       494\n",
            "   macro avg       0.90      0.89      0.89       494\n",
            "weighted avg       0.90      0.89      0.89       494\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nb_model.save(\"nb_pretrained.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqZGWl-fkGU5",
        "outputId": "991b5895-b8fd-4cd5-e54a-03e43c57205c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success! Naive Bayes exported to nb_pretrained.pkl.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_nb = NaiveBayesClassifier()\n",
        "new_nb.load_pretrained(\"nb_pretrained.pkl\")\n",
        "\n",
        "# 13 Make Predictions\n",
        "y_train_pred = nb_model.predict(X_train)\n",
        "y_test_pred = nb_model.predict(X_test)\n",
        "\n",
        "# 14 Evaluate Performance\n",
        "train_accuracy = accuracy(y_train, y_train_pred)\n",
        "test_accuracy = accuracy(y_test, y_test_pred)\n",
        "\n",
        "print(f\"\\nTraining Accuracy: {train_accuracy:.4f}\")\n",
        "print(f\"Testing Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "print(\"\\nClassification Report (Test Set):\")\n",
        "print(classification_report(y_test, y_test_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysHGvfkdkPUb",
        "outputId": "69cb26cf-38e6-444b-d5a9-fc95e4cd9fae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success! Pre-trained Naive Bayes loaded from nb_pretrained.pkl.\n",
            "\n",
            "Training Accuracy: 0.9035\n",
            "Testing Accuracy: 0.8927\n",
            "\n",
            "Classification Report (Test Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Pizza       0.86      0.94      0.90       164\n",
            "    Shawarma       0.90      0.90      0.90       165\n",
            "       Sushi       0.93      0.84      0.89       165\n",
            "\n",
            "    accuracy                           0.89       494\n",
            "   macro avg       0.90      0.89      0.89       494\n",
            "weighted avg       0.90      0.89      0.89       494\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from Voting import VotingClassifier as Voting\n",
        "\n",
        "# 12 Create Voting Classifier with Naive Bayes, Random Forest, and Logistic Regression\n",
        "voting_model = Voting(estimators=[('nb', new_nb), ('rf', rf_model), ('lr', lr_model)], voting='hard')\n",
        "voting_model.fit(X_train, y_train)\n",
        "\n",
        "# 13 Make Predictions\n",
        "y_train_pred = voting_model.predict(X_train)\n",
        "y_test_pred = voting_model.predict(X_test)\n",
        "\n",
        "# 14 Evaluate Performance\n",
        "train_accuracy = accuracy(y_train, y_train_pred)\n",
        "test_accuracy = accuracy(y_test, y_test_pred)\n",
        "\n",
        "print(f\"\\nTraining Accuracy: {train_accuracy:.4f}\")\n",
        "print(f\"Testing Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "print(\"\\nClassification Report (Test Set):\")\n",
        "print(classification_report(y_test, y_test_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnjaN427nDDy",
        "outputId": "a2e6ae69-07c1-40df-d085-a86b28188011"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Accuracy: 0.9687\n",
            "Testing Accuracy: 0.9109\n",
            "\n",
            "Classification Report (Test Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Pizza       0.87      0.96      0.92       164\n",
            "    Shawarma       0.92      0.89      0.91       165\n",
            "       Sushi       0.94      0.88      0.91       165\n",
            "\n",
            "    accuracy                           0.91       494\n",
            "   macro avg       0.91      0.91      0.91       494\n",
            "weighted avg       0.91      0.91      0.91       494\n",
            "\n"
          ]
        }
      ]
    }
  ]
}